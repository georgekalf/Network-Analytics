{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:12.331984Z",
     "start_time": "2021-12-13T22:58:11.028100Z"
    }
   },
   "outputs": [],
   "source": [
    "# %% Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os, glob, itertools\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from networkx.algorithms import degree_centrality\n",
    "from networkx.algorithms import eigenvector_centrality\n",
    "from networkx.algorithms import betweenness_centrality\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from networkx.algorithms.community import girvan_newman, modularity\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:12.340867Z",
     "start_time": "2021-12-13T22:58:12.332938Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading the xml file \n",
    "G = nx.read_graphml('trading_floor.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:12.348462Z",
     "start_time": "2021-12-13T22:58:12.342447Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating a dataframe\n",
    "df = pd.DataFrame.from_dict(dict(G.nodes(data=True)), orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:12.839102Z",
     "start_time": "2021-12-13T22:58:12.349642Z"
    }
   },
   "outputs": [],
   "source": [
    "# -- + inspecting/plotting the network\n",
    "fig = plt.figure(1, figsize=(24, 10))\n",
    "\n",
    "pos = nx.layout.spring_layout(G)\n",
    "ax0 = fig.add_subplot(1, 2, 1)\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "options = {\n",
    "    'node_color': 'darkgreen',\n",
    "    'alpha': 0.8,\n",
    "    'linewidths': 0.5,\n",
    "    'with_labels': False,\n",
    "    'font_color': 'black'\n",
    "}\n",
    "ax0.axis('off')\n",
    "nx.draw_networkx(G, pos=pos, **options, ax=ax0)\n",
    "\n",
    "# %% inspect the networkx\n",
    "# basic info\n",
    "pp(nx.info(G))\n",
    "\n",
    "# --+ draw the network\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, alpha=1, node_color='white')\n",
    "nx.draw_networkx_labels(G, pos, ax=ax)\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:14.159432Z",
     "start_time": "2021-12-13T22:58:12.839987Z"
    }
   },
   "outputs": [],
   "source": [
    "# Node distribution centrality plots\n",
    "# --+ degree of node\n",
    "degree = degree_centrality(G)\n",
    "# --+ degree distribution\n",
    "dc = nx.degree_centrality(G)\n",
    "# --+ eigenvector_centrality\n",
    "ec = nx.eigenvector_centrality(G)\n",
    "# --+ closeness centrality\n",
    "cc = nx.closeness_centrality(G)\n",
    "# --+ betweeness centrality\n",
    "bc = nx.betweenness_centrality(G)\n",
    "# save to data frame\n",
    "df1 = pd.DataFrame({\n",
    "    'eigenvector_centrality': ec,\n",
    "    'closeness_centrality': cc,\n",
    "    'betweenness_centrality': bc,\n",
    "    'degree_centrality': dc,\n",
    "})\n",
    "# --+ correlation matrix\n",
    "print(df1.corr())\n",
    "# --+ scatter plot matrix\n",
    "sns.pairplot(df1, palette=\"RdBu_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:14.164456Z",
     "start_time": "2021-12-13T22:58:14.160413Z"
    }
   },
   "outputs": [],
   "source": [
    "# picking the node with the highest centralities measures\n",
    "df1.idxmax(axis=0, skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:14.168133Z",
     "start_time": "2021-12-13T22:58:14.165279Z"
    }
   },
   "outputs": [],
   "source": [
    "# printing it out \n",
    "print(df1.iloc[[138]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:14.172109Z",
     "start_time": "2021-12-13T22:58:14.169137Z"
    }
   },
   "outputs": [],
   "source": [
    "# merging the 2 dataframes\n",
    "df = df.join(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:14.176507Z",
     "start_time": "2021-12-13T22:58:14.174493Z"
    }
   },
   "outputs": [],
   "source": [
    "# max and min degree of the nodes\n",
    "min_degree = min(degree.values())\n",
    "max_degree = max(degree.values())\n",
    "print(min_degree, max_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:14.358424Z",
     "start_time": "2021-12-13T22:58:14.177398Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ plot the degree centrality\n",
    "fig = plt.figure(figsize=(10, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "\n",
    "ax.hist(list(degree.values()), color='firebrick')\n",
    "ax.set_xlabel(\"degree centrality\", fontsize=10)\n",
    "ax.set_ylabel(\"count\", fontsize=10)\n",
    "\n",
    "ax.grid(ls='--', axis='y')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# --+ plot betweeness centrality\n",
    "ax1 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "ax1.hist(list(bc.values()), color=\"firebrick\")\n",
    "ax1.set_xlabel(\"betweeness centrality\", fontsize=10)\n",
    "ax1.set_ylabel(\"count\", fontsize=10)\n",
    "\n",
    "ax1.grid(ls='--', axis='y')\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['left'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:14.485241Z",
     "start_time": "2021-12-13T22:58:14.360311Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ create a list with degree of each node\n",
    "degrees = sorted([d for n, d in G.degree()], reverse=True)\n",
    "degrees\n",
    "\n",
    "pk = np.unique(degrees, return_counts=True)\n",
    "cpk = np.unique(degrees, return_index=True)\n",
    "\n",
    "# --+ visualising\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "\n",
    "ax0 = fig.add_subplot(1, 2, 1)\n",
    "ax1 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "ax0.scatter(pk[0],\n",
    "            pk[1] / len(degrees),\n",
    "            marker='o',\n",
    "            color='firebrick',\n",
    "            alpha=0.5)\n",
    "ax0.set_title('Point-to-point probability')\n",
    "ax0.set_xlabel('Degrees k')\n",
    "ax0.set_ylabel('Probability k=ki')\n",
    "ax0.spines['right'].set_visible(False)\n",
    "ax0.spines['top'].set_visible(False)\n",
    "\n",
    "ax1.scatter(cpk[0],\n",
    "            cpk[1] / len(degrees),\n",
    "            marker='o',\n",
    "            color='firebrick',\n",
    "            alpha=0.5)\n",
    "ax1.set_title('Cumulative probability')\n",
    "ax1.set_xlabel('Degrees k')\n",
    "ax1.set_ylabel('Probability k>=ki')\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "\n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:14.489142Z",
     "start_time": "2021-12-13T22:58:14.486500Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ converting the values of the dictionaries into lists\n",
    "dc = (list(dc.values()))\n",
    "bc = (list(bc.values()))\n",
    "cc = (list(cc.values()))\n",
    "ec = (list(ec.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:14.496150Z",
     "start_time": "2021-12-13T22:58:14.490292Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ Show the descriptive statistics of Degree Centrality\n",
    "\n",
    "print(\"\"\"\n",
    "==============================================\n",
    "    Summary stats on Degree Centrality\n",
    "==============================================\n",
    "Mean  :       {:.2f}\n",
    "Min   :       {:>5}\n",
    "Max   :       {:>5}\n",
    "Sigma :       {:.2f}\n",
    "\"\"\".format(np.mean(list(dc)), np.min(list(dc)), np.max(list(dc)),\n",
    "           np.std(list(dc))))\n",
    "\n",
    "# --+ Show the descriptive statistics of Betweeness Centrality\n",
    "\n",
    "print(\"\"\"\n",
    "==============================================\n",
    "    Summary stats on Betweeness Centrality \n",
    "==============================================\n",
    "Mean  :       {:.2f}\n",
    "Min   :       {:>5}\n",
    "Max   :       {:>5}\n",
    "Sigma :       {:.2f}\n",
    "\"\"\".format(np.mean(list(bc)), np.min(list(bc)), np.max(list(bc)),\n",
    "           np.std(list(bc))))\n",
    "\n",
    "# --+ Show the descriptive statistics of Closeness Centrality\n",
    "\n",
    "print(\"\"\"\n",
    "==============================================\n",
    "    Summary stats on Closeness Centrality \n",
    "==============================================\n",
    "Mean  :       {:.2f}\n",
    "Min   :       {:>5}\n",
    "Max   :       {:>5}\n",
    "Sigma :       {:.2f}\n",
    "\"\"\".format(np.mean(list(cc)), np.min(list(cc)), np.max(list(cc)),\n",
    "           np.std(list(cc))))\n",
    "\n",
    "# --+ Show the descriptive statistics of Eigenvector Centrality\n",
    "\n",
    "print(\"\"\"\n",
    "==============================================\n",
    "    Summary stats on Eigenvector Centrality\n",
    "==============================================\n",
    "Mean  :       {:.2f}\n",
    "Min   :       {:>5}\n",
    "Max   :       {:>5}\n",
    "Sigma :       {:.2f}\n",
    "\"\"\".format(np.mean(list(ec)), np.min(list(ec)), np.max(list(ec)),\n",
    "           np.std(list(ec))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assesing the modularity of the Network\n",
    "Detecting communities using Girwan-Newman "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:19.575605Z",
     "start_time": "2021-12-13T22:58:14.497473Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ plotting with 13 communities\n",
    "# fit\n",
    "solutions = girvan_newman(G)\n",
    "# --+ alternative paritioning solutions to consider\n",
    "k = 13\n",
    "# --+ register modularity scores\n",
    "modularity_scores = dict()\n",
    "# --+ iterate over solutions\n",
    "for community in itertools.islice(solutions, k):\n",
    "    solution = list(sorted(c) for c in community)\n",
    "    score = modularity(G, solution)\n",
    "    modularity_scores[len(solution)] = score\n",
    "# --+ plot modularity data\n",
    "fig = plt.figure()\n",
    "pos = list(modularity_scores.keys())\n",
    "values = list(modularity_scores.values())\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.stem(pos, values)\n",
    "ax.set_xticks(pos)\n",
    "ax.set_xlabel(r'Number of communities detected')\n",
    "ax.set_ylabel(r'Modularity score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the modularity score the number of communitites detected on our dataset is 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the greedy_modularity_communities function we are going to create a dataframe with the nodes and the community these nodes belong to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:19.600621Z",
     "start_time": "2021-12-13T22:58:19.576646Z"
    }
   },
   "outputs": [],
   "source": [
    "# finding how many communities this dataset has\n",
    "communities = list(nx.algorithms.community.greedy_modularity_communities(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:19.605010Z",
     "start_time": "2021-12-13T22:58:19.601609Z"
    }
   },
   "outputs": [],
   "source": [
    "# the plot above shows us the same result as in community number 13 we have the highest modularity\n",
    "len(communities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So based on both different ways of detecting communities in our dataset, it is observed that the size of 13 communities gives us the highest score of modularity\n",
    "\n",
    "Therefore, 13 communities are structured inside this large trading floor located in Canary Wharf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:19.608975Z",
     "start_time": "2021-12-13T22:58:19.606192Z"
    }
   },
   "outputs": [],
   "source": [
    "# creating a dataframe with nodes and in which community every node is detected\n",
    "commu_df = pd.DataFrame.from_records(communities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:19.612661Z",
     "start_time": "2021-12-13T22:58:19.609876Z"
    }
   },
   "outputs": [],
   "source": [
    "# renaming the rows into communities\n",
    "commu_df = commu_df.rename(\n",
    "    {\n",
    "        0: '1',\n",
    "        1: '2',\n",
    "        2: '3',\n",
    "        3: '4',\n",
    "        4: '5',\n",
    "        5: '6',\n",
    "        6: '7',\n",
    "        7: '8',\n",
    "        8: '9',\n",
    "        9: '10',\n",
    "        10: '11',\n",
    "        11: '12',\n",
    "        12: '13'\n",
    "    },\n",
    "    axis='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming our dataframe to make it easier for use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:19.616624Z",
     "start_time": "2021-12-13T22:58:19.613716Z"
    }
   },
   "outputs": [],
   "source": [
    "# chaning the order of the rows to make it easier in use\n",
    "df0 = commu_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:19.622514Z",
     "start_time": "2021-12-13T22:58:19.618009Z"
    }
   },
   "outputs": [],
   "source": [
    "# renaming the columns\n",
    "df0 = df0.rename(\n",
    "    columns={\n",
    "        0: 'cell.0',\n",
    "        1: 'cell.1',\n",
    "        2: 'cell.2',\n",
    "        3: 'cell.3',\n",
    "        4: 'cell.4',\n",
    "        5: 'cell.5',\n",
    "        6: 'cell.6',\n",
    "        7: 'cell.7',\n",
    "        8: 'cell.8',\n",
    "        9: 'cell.9',\n",
    "        10: 'cell.10',\n",
    "        11: 'cell.11',\n",
    "        12: 'cell.12',\n",
    "        13: 'cell.13',\n",
    "        14: 'cell.14',\n",
    "        15: 'cell.15',\n",
    "        16: 'cell.16',\n",
    "        17: 'cell.17',\n",
    "        18: 'cell.18',\n",
    "        19: 'cell.19',\n",
    "        20: 'cell.20',\n",
    "        21: 'cell.21',\n",
    "        22: 'cell.22'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:19.628912Z",
     "start_time": "2021-12-13T22:58:19.623634Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ transforming our dataframe in order to be able to merge later\n",
    "nodes = [c for c in df0 if c.startswith('cell.')]\n",
    "df0 = pd.melt(df0, id_vars='index', value_vars=nodes, value_name='nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:19.633068Z",
     "start_time": "2021-12-13T22:58:19.630268Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping the na rows\n",
    "df0.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:19.637672Z",
     "start_time": "2021-12-13T22:58:19.634805Z"
    }
   },
   "outputs": [],
   "source": [
    "# transforming column nodes into integer\n",
    "df0['nodes'] = df0['nodes'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:19.641170Z",
     "start_time": "2021-12-13T22:58:19.638686Z"
    }
   },
   "outputs": [],
   "source": [
    "# sorting values\n",
    "df0.sort_values('nodes', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:19.644655Z",
     "start_time": "2021-12-13T22:58:19.642030Z"
    }
   },
   "outputs": [],
   "source": [
    "# adding a column to show in which community every node belongs\n",
    "df['Community'] = df0['index'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualise in which community every node belongs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:20.050845Z",
     "start_time": "2021-12-13T22:58:19.645696Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ Visualisation of the communities\n",
    "fig = plt.figure(1, figsize=(24, 10))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax1 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "pos = nx.layout.spring_layout(G)\n",
    "\n",
    "colors = [\n",
    "    '#0343df', '#029386', '#f97306', '#01ff07', '#13eac9', '#cea2fd',\n",
    "    '#c04e01', '#610023', '#e2ca76', '#c65102', '#d5b60a', '#ff474c', '#fac205'\n",
    "]\n",
    "\n",
    "color_map = []\n",
    "for i in range(len(communities)):\n",
    "    for node in G.nodes():\n",
    "        if node in communities[i]:\n",
    "            color_map.append(colors[i])\n",
    "\n",
    "options = {\n",
    "    'node_color': color_map,\n",
    "    'alpha': 0.6,\n",
    "    'width': 1,\n",
    "    'linewidths': 0.1,\n",
    "    'with_labels': True,\n",
    "    'font_color': 'black'\n",
    "}\n",
    "\n",
    "nx.draw_networkx(G, pos=pos, **options, ax=ax)\n",
    "# --+ Visualisation of traders based on preference of adopting ai in the trading floor\n",
    "options = {\n",
    "    'node_color': df['ai'],\n",
    "    'alpha': 1,\n",
    "    'width': 1,\n",
    "    'linewidths': 0.1,\n",
    "    'with_labels': False,\n",
    "    'font_color': 'black'\n",
    "}\n",
    "\n",
    "nx.draw_networkx(G, pos=pos, **options, cmap='coolwarm', ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the position coordinates to our nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:20.060135Z",
     "start_time": "2021-12-13T22:58:20.055808Z"
    }
   },
   "outputs": [],
   "source": [
    "# adding the new column of the coordinates in our existing dataframe\n",
    "df['position'] = df[['x_pos', 'y_pos']].apply(tuple, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:20.450869Z",
     "start_time": "2021-12-13T22:58:20.061040Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ Visualisation based on the position of each node and the community that belongs to\n",
    "fig = plt.figure(1, figsize=(23, 10))\n",
    "ax0 = fig.add_subplot(1, 2, 1)\n",
    "ax1 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "pos = nx.layout.spring_layout(G)\n",
    "# --+ coordinate & communities\n",
    "nx.draw_networkx_nodes(G,\n",
    "                       pos=df['position'],\n",
    "                       node_color=df['Community'].apply(lambda x: int(x) - 1),\n",
    "                       alpha=df['ai'] / 10,\n",
    "                       node_size=df['ai'] * 55,\n",
    "                       cmap=plt.cm.jet,\n",
    "                       ax=ax0)\n",
    "# --+ coordinates & ai preference\n",
    "nx.draw_networkx(G,\n",
    "                 pos=df['position'],\n",
    "                 node_color=df['ai'],\n",
    "                 cmap=plt.cm.coolwarm,\n",
    "                 with_labels=True,\n",
    "                 ax=ax1)\n",
    "# --+ dark red means highest AI preference adoption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving to our next step, let's analyse if distance between nodes in the trading floor(in combination with the community), play a significant role in adopting AI or no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:20.458060Z",
     "start_time": "2021-12-13T22:58:20.451696Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ dyadic similarity (based on preferences on adopting ai or no)\n",
    "starting_point = []\n",
    "ending_point = []\n",
    "similarity = {}\n",
    "score = []\n",
    "for u, v in G.edges():\n",
    "    key = \"{}-{}\".format(u, v)\n",
    "    starting_point.append(u)\n",
    "    ending_point.append(v)\n",
    "    value = np.abs(G.nodes[u][\"ai\"] - G.nodes[v][\"ai\"])\n",
    "    similarity[key] = value\n",
    "    score.append(value)\n",
    "# --+ score of similarity between the two nodes\n",
    "\n",
    "# --+ creating a dataframe of the starting, ending point and the score of similarity between these two nodes\n",
    "df_similarity = pd.DataFrame()\n",
    "df_similarity['starting_point'] = pd.DataFrame(starting_point)\n",
    "df_similarity['ending_point'] = pd.DataFrame(ending_point)\n",
    "df_similarity['score'] = pd.DataFrame(score)\n",
    "# --+ similarity score meaning how much difference in the preference of adopting AI two nodes have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:20.469130Z",
     "start_time": "2021-12-13T22:58:20.459024Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ creating a new dataframe with a starting-ending point (based on the x_pos and y_pos)\n",
    "starting_x = []\n",
    "starting_y = []\n",
    "ending_x = []\n",
    "ending_y = []\n",
    "for i in starting_point:\n",
    "    starting_x.append(df['x_pos'][i])\n",
    "for i in starting_point:\n",
    "    starting_y.append(df['y_pos'][i])\n",
    "for i in ending_point:\n",
    "    ending_x.append(df['x_pos'][i])\n",
    "for i in ending_point:\n",
    "    ending_y.append(df['y_pos'][i])\n",
    "\n",
    "df_similarity['starting_x'] = starting_x\n",
    "df_similarity['starting_y'] = starting_y\n",
    "df_similarity['ending_x'] = ending_x\n",
    "df_similarity['ending_y'] = ending_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:20.473084Z",
     "start_time": "2021-12-13T22:58:20.469974Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ preparing to calculate the distance between the nodes\n",
    "df_similarity['sq'] = (\n",
    "    (df_similarity['starting_x'] - df_similarity['ending_x'])**2 +\n",
    "    (df_similarity['starting_y'] - df_similarity['ending_y'])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:20.484265Z",
     "start_time": "2021-12-13T22:58:20.473891Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ distance\n",
    "df_similarity['distance'] = (df_similarity['sq'])**0.5\n",
    "# --+ dropping unnecessary column\n",
    "df_similarity.drop(['sq'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:20.654150Z",
     "start_time": "2021-12-13T22:58:20.485145Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ visualise distance - similarity\n",
    "sns.scatterplot(x='score', y='distance', hue='score', data=df_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:20.718694Z",
     "start_time": "2021-12-13T22:58:20.655384Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ running OLS regression\n",
    "x = df_similarity['score']\n",
    "y = df_similarity['distance']\n",
    "FML = 'y ~ x'\n",
    "OLS = smf.ols(FML, data=df_similarity).fit()\n",
    "print(OLS.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion and Cascading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:20.727873Z",
     "start_time": "2021-12-13T22:58:20.719674Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ creating a function for the diffusion-cascading process\n",
    "def difussion(n):\n",
    "    df['Adopters'] = (df['ai'] >= n)\n",
    "\n",
    "    p = df['Adopters']\n",
    "    for i in sorted(G.nodes()):\n",
    "        G.nodes[i]['adopting'] = p[i]\n",
    "\n",
    "    colors = []\n",
    "    for i in G.nodes():\n",
    "        if G.nodes[i]['adopting'] == True:\n",
    "            colors.append('green')\n",
    "        else:\n",
    "            colors.append('grey')\n",
    "# creating the figure\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    ax = fig.add_subplot(1, 2, 1)\n",
    "    ax0 = fig.add_subplot(1, 2, 2)\n",
    "    ax.axis('off')\n",
    "\n",
    "    nx.draw_networkx(G,\n",
    "                     pos=df['position'],\n",
    "                     with_labels=False,\n",
    "                     node_color=colors,\n",
    "                     edge_color='black',\n",
    "                     node_size=df['ai'] * 45,\n",
    "                     ax=ax,\n",
    "                     alpha=0.5)\n",
    "\n",
    "    # ---+ calculating the percentage of traders before the diffusion\n",
    "    adopters = nx.get_node_attributes(G, 'adopting')\n",
    "    adopt = []\n",
    "    for i in adopters.values():\n",
    "        adopt.append(i)\n",
    "\n",
    "    print(\"The percentage of traders in adopting AI before diffusion is\",\n",
    "          str(round(np.mean(adopt) * 100)) + '%.')\n",
    "    # --+ initialize the diffusion process\n",
    "    # nodes making decisions\n",
    "    for focal in G.nodes:\n",
    "        # --+ pay-off of adopting the new behavior\n",
    "        a = 1 + df['ai'][focal] / 10\n",
    "        # --+ pay-off of the status quo (not changing)\n",
    "        b = 1 + (1 - (df['ai'][focal] / 10))\n",
    "        # count adopting neighbors\n",
    "        focal_nbrs = list(G.neighbors(focal))\n",
    "        p = np.sum([G.nodes[nbr]['adopting'] for nbr in focal_nbrs])\n",
    "        # pay-off of adopting new behavior\n",
    "        d = G.degree(focal)\n",
    "        a_payoff = p * a\n",
    "        b_payoff = (d - p) * b\n",
    "        # decision to adopt\n",
    "        if (G.nodes[focal]['adopting'] == False) & (a_payoff > b_payoff):\n",
    "            G.nodes[focal]['adopting'] = True\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "# %% draw the network (green are the early adopters based on the score they range in ai column)\n",
    "    colors = []\n",
    "    for n in G.nodes():\n",
    "        if G.nodes[n]['adopting'] == True:\n",
    "            colors.append('green')\n",
    "        else:\n",
    "            colors.append('grey')\n",
    "\n",
    "    nx.draw(G,\n",
    "            pos=df['position'],\n",
    "            with_labels=False,\n",
    "            node_color=colors,\n",
    "            node_size=df['ai'] * 45,\n",
    "            ax=ax0,\n",
    "            alpha=0.9)\n",
    "\n",
    "    # ---+ calculating the percentage of traders of adopting AI\n",
    "    adopters = nx.get_node_attributes(G, 'adopting')\n",
    "    adopt = []\n",
    "    for i in adopters.values():\n",
    "        adopt.append(i)\n",
    "\n",
    "    print(\"The percentage of traders in adopting AI after difussion is\",\n",
    "          str(round(np.mean(adopt) * 100)) + \"%.\")\n",
    "    return difussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-13T22:58:20.882377Z",
     "start_time": "2021-12-13T22:58:20.728889Z"
    }
   },
   "outputs": [],
   "source": [
    "# --+ the function\n",
    "difussion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "14ca62385630e80b5c4ce7904863b62bddb6543d945de0683be07a870abfe95e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
